{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMjzGsPmUOfq39WQ0FueuOf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moulinath/Cloud-Certifications/blob/master/NLP_Healthcare%20Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AFQaQaNGJJu",
        "outputId": "66c186c6-dc65-4aa8-bbf4-a7e238622ac5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pycrf in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.7/dist-packages (0.3.6)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (4.64.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (1.15.0)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (0.9.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite) (0.8.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn==0.22.2 in /root/.local/lib/python3.7/site-packages (0.22.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.2) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.2) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.2) (1.4.1)\n"
          ]
        }
      ],
      "source": [
        "# Import and install required packages\n",
        "\n",
        "!pip install pycrf\n",
        "!pip install sklearn-crfsuite\n",
        "! pip install scikit-learn==0.22.2 --user\n",
        "\n",
        "import spacy\n",
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import metrics\n",
        "\n",
        "model = spacy.load(\"en_core_web_sm\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Need to pre-process the data to recover the complete sentences and their labels."
      ],
      "metadata": {
        "id": "46pOixbBX9O2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will construct proper sentences from individual words and print the first 5 sentences."
      ],
      "metadata": {
        "id": "kPR62Zj6b9h8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "xWDxL4fvKWWd"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to process the file and return a sentence list\n",
        "def prep_inputfile(input_file):\n",
        "    i_file = open(input_file, 'r')\n",
        "    file_name = i_file.readlines()\n",
        "    i_file.close()\n",
        "\n",
        "    output_list = []\n",
        "\n",
        "    full_sentence = \"\"\n",
        "\n",
        "    for each_word in file_name:\n",
        "        each_word = each_word.strip()\n",
        "        if each_word == \"\":\n",
        "            output_list.append(full_sentence) # To append the complete sentence to the output list\n",
        "            full_sentence = \"\" # For new sentence start\n",
        "        else:\n",
        "            if full_sentence:\n",
        "                full_sentence += \" \" + each_word\n",
        "            else:\n",
        "                full_sentence = each_word\n",
        "                \n",
        "    return output_list\n",
        "\n"
      ],
      "metadata": {
        "id": "penM8MlKLWuv"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentence = prep_inputfile('/train_sent ')\n",
        "train_label = prep_inputfile('/train_label ')\n",
        "test_sentence = prep_inputfile('/test_sent ')\n",
        "test_label = prep_inputfile('/test_label ')\n"
      ],
      "metadata": {
        "id": "jRhZX23RLgQX"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will count the number of sentences in the processed train and test datasetÂ¶"
      ],
      "metadata": {
        "id": "O8UqDgOEcMc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print first five sentences from the processed dataset\n",
        "for each_item in range(5):\n",
        "    print(f\"Sentence {each_item+1} is: {train_sentence[each_item]}\")\n",
        "    print(f\"Label {each_item+1} is: {train_label[each_item]}\")\n",
        "    print(\"*\"*100)\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCYs8xulNiUe",
        "outputId": "07df0c48-9759-461a-a713-fd801b358392"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1 is: All live births > or = 23 weeks at the University of Vermont in 1995 ( n = 2395 ) were retrospectively analyzed for delivery route , indication for cesarean , gestational age , parity , and practice group ( to reflect risk status )\n",
            "Label 1 is: O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
            "****************************************************************************************************\n",
            "Sentence 2 is: The total cesarean rate was 14.4 % ( 344 of 2395 ) , and the primary rate was 11.4 % ( 244 of 2144 )\n",
            "Label 2 is: O O O O O O O O O O O O O O O O O O O O O O O O O\n",
            "****************************************************************************************************\n",
            "Sentence 3 is: Abnormal presentation was the most common indication ( 25.6 % , 88 of 344 )\n",
            "Label 3 is: O O O O O O O O O O O O O O O\n",
            "****************************************************************************************************\n",
            "Sentence 4 is: The `` corrected '' cesarean rate ( maternal-fetal medicine and transported patients excluded ) was 12.4 % ( 273 of 2194 ) , and the `` corrected '' primary rate was 9.6 % ( 190 of 1975 )\n",
            "Label 4 is: O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
            "****************************************************************************************************\n",
            "Sentence 5 is: Arrest of dilation was the most common indication in both `` corrected '' subgroups ( 23.4 and 24.6 % , respectively )\n",
            "Label 5 is: O O O O O O O O O O O O O O O O O O O O O O\n",
            "****************************************************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"No. of sentences in processed train dataset is: {len(train_sentence)}\")\n",
        "print(f\"No. of sentences in processed test dataset is: {len(test_sentence)}\")\n",
        "\n",
        "\n",
        "print(f\"No. of lines of labels in processed train dataset is: {len(train_label)}\")\n",
        "print(f\"No. of lines of labels in processed test dataset is: {len(test_label)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQ_LRbwrNnFy",
        "outputId": "c15d1d37-6c89-498b-846e-65ac9dc13d3e"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of sentences in processed train dataset is: 2599\n",
            "No. of sentences in processed test dataset is: 1056\n",
            "No. of lines of labels in processed train dataset is: 2599\n",
            "No. of lines of labels in processed test dataset is: 1056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Concept Identification\n",
        "\n",
        "We will first explore what are the various concepts present in the dataset. For this, we will use PoS Tagging.\n",
        "\n",
        "Extract those tokens which have NOUN or PROPN as their PoS tag and find their frequency\n",
        "\n"
      ],
      "metadata": {
        "id": "sgBRPwT5cUTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a list to hold all the tokens which are either NOUN or PROPER NOUN\n",
        "noun_propn_tokens_list = []\n",
        "\n",
        "\n",
        "# Each token which is a NOUN or PROPN will be appended to the list \"noun_propn_tokens_list\"\n",
        "for sentences in (train_sentence, test_sentence):\n",
        "    for sent in sentences:\n",
        "        processed_sent = model(sent)\n",
        "        for each_token in processed_sent:\n",
        "            if each_token.pos_ == \"NOUN\" or each_token.pos_ == \"PROPN\":\n",
        "                noun_propn_tokens_list.append(each_token.text)\n",
        "                \n",
        "                \n",
        "# Creating a Series to hold the tokens which are either NOUN or PROPER NOUN\n",
        "def_noun_propn = pd.Series(noun_propn_tokens_list)\n"
      ],
      "metadata": {
        "id": "TRkLWbrLNtM0"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will print the top 25 most common tokens with NOUN or PROPN PoS tags"
      ],
      "metadata": {
        "id": "BMnkxlhfcem2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the count of each token and sorting the data in top 25 most token counts\n",
        "def_noun_propn.value_counts().sort_values(ascending=False).head(25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOlSWYaIOPdw",
        "outputId": "10935e48-2ea0-4c21-e6fc-33ec40a9846b"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "patients        492\n",
              "treatment       281\n",
              "%               247\n",
              "cancer          200\n",
              "therapy         175\n",
              "study           152\n",
              "disease         141\n",
              "cell            140\n",
              "lung            116\n",
              "group            94\n",
              "chemotherapy     88\n",
              "gene             87\n",
              "effects          85\n",
              "results          78\n",
              "women            77\n",
              "use              74\n",
              "risk             71\n",
              "surgery          71\n",
              "cases            71\n",
              "analysis         70\n",
              "rate             67\n",
              "response         66\n",
              "survival         65\n",
              "children         64\n",
              "effect           63\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining features for CRF"
      ],
      "metadata": {
        "id": "yTjiycbnck-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's define the features to get the feature value for one word.\n",
        "def getFeaturesForAWord(sentence, pos, pos_tags):\n",
        "  word = sentence[pos]\n",
        "\n",
        "  features = [\n",
        "    'word.lower=' + word.lower(), # serves as word id\n",
        "    'word[-3:]=' + word[-3:],     # last three characters\n",
        "    'word[-2:]=' + word[-2:],     # last two characters\n",
        "    'word.isupper=%s' % word.isupper(),  # is the word in all uppercase\n",
        "    'word.isdigit=%s' % word.isdigit(),  # is the word a number\n",
        "    'word.startsWithCapital=%s' % word[0].isupper(), # is the word starting with a capital letter\n",
        "    'word.pos=' + pos_tags[pos]\n",
        "  ]\n",
        "\n",
        "  #Use the previous word also while defining features\n",
        "  if(pos > 0):\n",
        "    prev_word = sentence[pos-1]\n",
        "    features.extend([\n",
        "    'prev_word.lower=' + prev_word.lower(), \n",
        "    'prev_word.isupper=%s' % prev_word.isupper(),\n",
        "    'prev_word.isdigit=%s' % prev_word.isdigit(),\n",
        "    'prev_word.startsWithCapital=%s' % prev_word[0].isupper(),\n",
        "    'prev_word.pos=' + pos_tags[pos-1]\n",
        "  ])\n",
        "  # Mark the begining and the end words of a sentence correctly in the form of features.\n",
        "  else:\n",
        "    features.append('BEG') # feature to track begin of sentence \n",
        "\n",
        "  if(pos == len(sentence)-1):\n",
        "    features.append('END') # feature to track end of sentence\n",
        "\n",
        "  return features\n"
      ],
      "metadata": {
        "id": "NUvJXgPFOU_S"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting the Features"
      ],
      "metadata": {
        "id": "vvm4uVOtctai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will create a function to get the features for a sentenceÂ¶"
      ],
      "metadata": {
        "id": "1iSY_sG5cxa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a code to get features for a sentence.\n",
        "# Function to get features for a sentence.\n",
        "def getFeaturesForASentence(sentence):\n",
        "    \n",
        "    # We need to get the pos_tags to be passed to the function\n",
        "    processed_sent = model(sentence)\n",
        "    postags = []\n",
        "    \n",
        "    for each_token in processed_sent:\n",
        "        postags.append(each_token.pos_)\n",
        "    \n",
        "    sentence_list = sentence.split()\n",
        "    return [getFeaturesForAWord(sentence_list, pos, postags) for pos in range(len(sentence_list))]\n"
      ],
      "metadata": {
        "id": "TitNTZbMOZ5v"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will create a function to get the labels of a sentenceÂ¶"
      ],
      "metadata": {
        "id": "wdfEiBImc5eS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a code to get the labels for a sentence.\n",
        "# Function to get the labels for a sentence.\n",
        "def getLabelsInListForASentence(labels):\n",
        "  return labels.split()"
      ],
      "metadata": {
        "id": "jbgjocFxOdIz"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will define the  input and target variables"
      ],
      "metadata": {
        "id": "JAQSCCNddAtX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will define the features' values for each sentence as input variable for CRF model in test and train datasets\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nlsfZVi2dJri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = [getFeaturesForASentence(sentence) for sentence in train_sentences]\n",
        "X_test = [getFeaturesForASentence(sentence) for sentence in test_sentences]"
      ],
      "metadata": {
        "id": "pEINexsSOgTh"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will define the labels as the target variable for test and the train dataset"
      ],
      "metadata": {
        "id": "AqBek6indUdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train = [getLabelsInListForASentence(labels) for labels in train_labels]\n",
        "Y_test = [getLabelsInListForASentence(labels) for labels in test_labels]"
      ],
      "metadata": {
        "id": "cSH8ubljOjFg"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the CRF Model"
      ],
      "metadata": {
        "id": "YnaDRuJ3dbfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the CRF model.\n",
        "\n",
        "crf = sklearn_crfsuite.CRF(max_iterations=100)\n",
        "crf.fit(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpfJw6YsOv01",
        "outputId": "e1c90e9c-dfc4-42e3-ccdc-4038bad729ad"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.local/lib/python3.7/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRF(algorithm=None, all_possible_states=None, all_possible_transitions=None,\n",
              "    averaging=None, c=None, c1=None, c2=None, calibration_candidates=None,\n",
              "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
              "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
              "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
              "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
              "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation"
      ],
      "metadata": {
        "id": "e3Kjz0TWdge4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HK7fNM4Rd5m8"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will have to predict the labels of each of the tokens in each sentence of the test dataset that has already been pre-processed"
      ],
      "metadata": {
        "id": "SI_8NB9wdi2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = crf.predict(X_test)"
      ],
      "metadata": {
        "id": "4A0i3uWjP1Xt"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will calculate the f1 score using the actual labels and the predicted labels of the test dataset."
      ],
      "metadata": {
        "id": "TcAx3pGnd0uJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score = metrics.flat_f1_score(Y_test, Y_pred, average='weighted')\n",
        "print(f\"F1 score : {round(f1_score,4)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCJVR2WeP58h",
        "outputId": "4449fcf1-82a3-4365-bb9c-12691fb6735e"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score : 0.9043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identifying Diseases and Treatments using Custom NER\n",
        "\n",
        "We will now use the CRF model's prediction to prepare a record of diseases identified in the corpus and treatments used for the diseases."
      ],
      "metadata": {
        "id": "SVnvuu0weDKR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will have to get all the predicted treatments (T) labels corresponding to each disease (D) label in the test dataset."
      ],
      "metadata": {
        "id": "fZJPt-rHeO8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an empty dictionary to hold diseases and their corresponding treatments\n",
        "Dis_Treat_dict = dict()\n",
        "\n",
        "for i in range(len(Y_pred)):\n",
        "    # Get the predicted labels of each test sentence into \"val\"\n",
        "    val = Y_pred[i]\n",
        "    \n",
        "    # Empty strings to store the values of Diseases and Treatments\n",
        "    Diseases = \"\"\n",
        "    Treatments = \"\"\n",
        "    \n",
        "    # Each loop will iterate through the individual labels and focus on mapping D and T labels\n",
        "    # with Diseases and Treatments within each sentence into a concatenated string\n",
        "    for j in range(len(val)):\n",
        "        if val[j] == 'D': # If label is D, it indicates a Disease \n",
        "            Diseases += test_sentences[i].split()[j] + \" \"\n",
        "        elif val[j] == 'T': # If label is T, it indicates a Treatment\n",
        "            Treatments += test_sentences[i].split()[j] + \" \"\n",
        "            \n",
        "    # Removes any extra whitespaces to either end of the string\n",
        "    Diseases = Diseases.lstrip().rstrip()\n",
        "    Treatments = Treatments.lstrip().rstrip()\n",
        "\n",
        "    # If Diseases and Treatments are blank, ignore them\n",
        "    # If Disease is not present in Dictionary, add it along with the corresponding treatment\n",
        "    # If Disease is present in the Dictionary, append the treatments for that diseases with existing\n",
        "    # treatments\n",
        "    if Diseases != \"\" and Treatments != \"\":\n",
        "        if Diseases in Dis_Treat_dict.keys():\n",
        "            treat_out = list(Dis_Treat_dict[Diseases])\n",
        "            treat_out.append(Treatments)\n",
        "            Dis_Treat_dict[Diseases] = treat_out\n",
        "        elif Diseases not in Dis_Treat_dict.keys():\n",
        "            Dis_Treat_dict[Diseases] = Treatments"
      ],
      "metadata": {
        "id": "qE3cULnXQCG1"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting the treatment for the disease name: 'hereditary retinoblastoma'"
      ],
      "metadata": {
        "id": "ce5lSveleWTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Dis_Treat_dict['hereditary retinoblastoma']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nVVes-lXQDsB",
        "outputId": "cf7e547f-80e9-4f56-8474-1219b8d7027c"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'radiotherapy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    }
  ]
}